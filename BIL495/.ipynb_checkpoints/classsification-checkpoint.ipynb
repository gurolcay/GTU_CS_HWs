{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- unicode: utf-8 -*-\n",
    "from __future__ import division\n",
    "import os \n",
    "import json\n",
    "import math\n",
    "import codecs\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name is 'nt':\n",
    "    file_path_delim = '\\\\'\n",
    "    dataset_path = '\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\'\n",
    "elif os.name is 'posix':\n",
    "    file_path_delim = '/'\n",
    "    dataset_path = '/dataSets/kose_yazarlari/kose_yazilari/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Can_Dundar',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Cuneyt_Ozdemir',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Ece_Temelkuran',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Emre_Uslu',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Ilber_Ortayli',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Ismail_Kucukkaya',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Mustafa_Balbay',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Samil_Tayyar',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Ugur_Dundar',\n",
       " 'C:\\\\Users\\\\Gurol\\\\Documents\\\\Lessons\\\\BIL495\\\\Codes\\\\BIL495\\\\dataSets\\\\kose_yazarlari\\\\kose_yazilari\\\\Yekta_Kopan']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "relative_path = os.getcwd() + dataset_path\n",
    "\n",
    "tokenizer = lambda doc: doc.lower().split(\" \")\n",
    "\n",
    "datas_path = [relative_path + f for f in os.listdir(relative_path)]\n",
    "\n",
    "datas_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can_Dundar',\n",
       " 'Cuneyt_Ozdemir',\n",
       " 'Ece_Temelkuran',\n",
       " 'Emre_Uslu',\n",
       " 'Ilber_Ortayli',\n",
       " 'Ismail_Kucukkaya',\n",
       " 'Mustafa_Balbay',\n",
       " 'Samil_Tayyar',\n",
       " 'Ugur_Dundar',\n",
       " 'Yekta_Kopan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_names = [p[p.rfind(file_path_delim)+1:] for p in writers_path]\n",
    "\n",
    "writer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(file_path):\n",
    "    with codecs.open(file_path,'r',encoding='utf-8', errors='ignore') as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data( file_path_list ):\n",
    "\n",
    "    X = [] # inputs\n",
    "    y = [] # labels\n",
    "\n",
    "    for i in range(0,len(file_path_list)):\n",
    "        for f in os.listdir(file_path_list[i]):\n",
    "            if f.startswith('.'):\n",
    "                continue\n",
    "            else: \n",
    "                X.append(read_from_file(file_path_list[i] + file_path_delim + f))\n",
    "                y.append(i)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data(datas_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c7fe1c7b30da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm='l2', min_df=0.05, use_idf=True, smooth_idf=False, sublinear_tf=True,tokenizer=tokenizer)\n",
    "\n",
    "t0 = time()\n",
    "X_train = vectorizer.fit_transform(X_data)\n",
    "duration = time() - t0\n",
    "\n",
    "'X_train duration time: ', duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "X_test = vectorizer.transform(X_test)\n",
    "duration = time() - t0\n",
    "\n",
    "'X_test duration time: ', duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print('Training')\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_data)\n",
    "    train_time = time() - t0\n",
    "    print('Train time: %0.3fs' % train_time)\n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print('Test time: %0.3fs' % test_time)\n",
    "    \n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print('accuracy: %0.3f' % score)\n",
    "    \n",
    "#     if hasattr(clf, 'coef_'):\n",
    "#         print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "#         print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "#         if opts.print_top10 and feature_names is not None:\n",
    "#             print(\"top 10 keywords per class:\")\n",
    "#             for i, label in enumerate(target_names):\n",
    "#                 top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "#                 print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "#         print()\n",
    "\n",
    "#     if opts.print_report:\n",
    "#         print(\"classification report:\")\n",
    "#         print(metrics.classification_report(y_test, pred,\n",
    "#                                             target_names=target_names))\n",
    "\n",
    "#     if opts.print_cm:\n",
    "#         print(\"confusion matrix:\")\n",
    "#         print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "            (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "            (RandomForestClassifier(n_estimators=100), \"Random Forest\"),\n",
    "            (DecisionTreeClassifier(random_state=0), \"Decision Tree\")):\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty=penalty)))\n",
    "\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\", color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
