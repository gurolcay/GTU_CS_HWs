{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- unicode: utf-8 -*-\n",
    "from __future__ import division\n",
    "import os \n",
    "import json\n",
    "import math\n",
    "import codecs\n",
    "import string\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name is 'nt':\n",
    "    file_path_delim = '\\\\'\n",
    "    dataset_path = '\\\\dataSets\\\\tweets\\\\tweets.json'\n",
    "elif os.name is 'posix':\n",
    "    file_path_delim = '/'\n",
    "    dataset_path = '/dataSets/tweets/tweets.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dump_file_name = \"tweets_vectors.pickle\"\n",
    "user_ids_file_name = \"user_ids.pickle\"\n",
    "users_document = \"users_document.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gurol/Google Drive/lessons2017/Lessons/Bil495/Codes/BIL495/dataSets/tweets/tweets.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.getcwd() + dataset_path\n",
    "\n",
    "tokenizer = lambda doc: doc.lower().split(\" \")\n",
    "\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = json.load(open(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm='l2', min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from json file to dictionary and return\n",
    "def read_data(datas):\n",
    "    tweets = {} # input\n",
    "    \n",
    "    for data in datas:\n",
    "        uid = data.get('UserID')\n",
    "        if uid in tweets.keys():\n",
    "            tweets[uid].append(data.get('TextText'))\n",
    "        else:\n",
    "            tweets.update({uid:[]})\n",
    "            tweets[uid].append(data.get('TextText'))\n",
    "            \n",
    "    return tweets\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge every each user tweets\n",
    "def merge_tweets(tweets):\n",
    "    merged_tweets = {}\n",
    "\n",
    "    for user_key in tweets.keys():\n",
    "        merged_tweets[user_key] = ''\n",
    "        for tweet in tweets[user_key]:\n",
    "            merged_tweets[user_key] += '\\n' + tweet\n",
    "\n",
    "    return merged_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document for every each user\n",
    "def create_document_for_each_users(merged_tweets):\n",
    "    documents = []\n",
    "    for user_key in merged_tweets.keys():\n",
    "        documents.append(merged_tweets[user_key])\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it makes accessible to user ids via index\n",
    "def prepair_index_for_user_ids(merged_tweets):\n",
    "    user_ids = {}\n",
    "    for i, key in zip(range(len(merged_tweets.keys())), merged_tweets.keys()):\n",
    "        user_ids[i] = key\n",
    "    \n",
    "    return user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write vectors and user_ids to file\n",
    "def write_to_file(vectors, user_ids, documents):\n",
    "    with open(vector_dump_file_name, \"wb\") as vectors_file:\n",
    "        pickle.dump(vectors, vectors_file)\n",
    "        \n",
    "    with open(user_ids_file_name,\"wb\") as ids_file:\n",
    "        pickle.dump(user_ids, ids_file)\n",
    "        \n",
    "    with open(users_document,\"wb\") as documents_file:\n",
    "        pickle.dump(documents, documents_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging tweets\n",
      "Creating documents for every each user\n"
     ]
    }
   ],
   "source": [
    "tweets = read_data(datas)\n",
    "print('Merging tweets')\n",
    "merged_tweets = merge_tweets(tweets)\n",
    "print('Creating documents for every each user')\n",
    "documents = create_document_for_each_users(merged_tweets)\n",
    "user_ids = prepair_index_for_user_ids(merged_tweets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets_vector = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(user_tweets_vector, user_ids, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 774760)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
